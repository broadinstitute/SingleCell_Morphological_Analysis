{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce3868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:jupyter_black:config: {'line_length': 79, 'target_versions': {<TargetVersion.PY310: 10>}}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            (function() {\n",
       "                jb_set_cell(\"datasets = [\\\"jump_orf\\\", \\\"jump_crispr\\\"]\\n\\nsymbol_col = {\\n    \\\"jump_crispr\\\": \\\"Metadata_Symbol\\\",\\n    \\\"jump_orf\\\": \\\"Metadata_Symbol\\\",\\n    \\\"taorf\\\": \\\"Metadata_gene_name\\\",\\n}\\n\\ndf_ls = []\\n# names=[]\\nds_symbols = {}\\nds_features = {}\\nfor dataset in datasets:\\n    #     names.append(dataset)\\n    annot = pd.read_csv(\\n        mito_project_root_dir\\n        + \\\"/workspace/metadata/preprocessed/annot_\\\"\\n        + dataset\\n        + \\\".csv\\\",\\n        dtype={\\\"Metadata_Plate\\\": str},\\n    )\\n    if \\\"Metadata_Source\\\" not in annot.columns:\\n        annot[\\\"Metadata_Source\\\"] = \\\"broad\\\"\\n    # target_features_list = ds_info_dict[dataset][\\\"target_features_list\\\"]\\n    # sources = ['source_5']\\n    sources = annot[\\\"Metadata_Source\\\"].unique()\\n    for si in sources:\\n        file_path = (\\n            save_results_dir\\n            + \\\"/preprocessed_data/\\\"\\n            + dataset\\n            + \\\"_df_rep_level_scaled_\\\"\\n            + si\\n            + \\\".csv\\\"\\n        )\\n        if os.path.exists(file_path):\\n            df_rep_level_scaled = pd.read_csv(file_path)\\n\\n            ds_symbols[dataset] = (\\n                df_rep_level_scaled[symbol_col[dataset]].unique().tolist()\\n            )\\n\\n            (\\n                cp_features,\\n                cp_features_analysis_0,\\n            ) = extract_cpfeature_names.extract_cpfeature_names(\\n                df_rep_level_scaled\\n            )\\n\\n            ds_features[dataset] = cp_features_analysis_0\\n\\n            #             df_rep_level_scaled['']\\n\\n            #         batch_names_cols = DS_X_featureQ_rank_df.columns[\\n            #             DS_X_featureQ_rank_df.columns.str.contains(\\\"^average_std_score_\\\")\\n            #         ].tolist()\\n            df_ls.append(df_rep_level_scaled)\")\n",
       "            })();\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "import black\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load(\n",
    "    lab=False,\n",
    "    line_length=79,\n",
    "    verbosity=\"DEBUG\",\n",
    "    target_version=black.TargetVersion.PY310,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as sp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "# import dask.dataframe as dd\n",
    "# import dask.config\n",
    "# dask.config.set({\"distributed.scheduler.allowed-failures\": 10})\n",
    "today = date.today()\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/workspace_SingleCell/SingleCell_Morphological_Analysis/') \n",
    "from singlecell.read import read_single_cell_sql\n",
    "from singlecell.preprocess import handle_nans, extract_cpfeature_names,find_highly_correlated_features\n",
    "from singlecell.visualize import visualize_n_SingleCell, cluster\n",
    "from singlecell.process import statistical_tests,precision_recall\n",
    "from singlecell.preprocess.filter_out_edge_single_cells import edgeCellFilter\n",
    "from singlecell.save.save_pandas_dfs import saveDF_to_CSV_GZ_no_timestamp\n",
    "from singlecell.preprocess.control_for_cellcount import control_feature_y_for_variable_x\n",
    "from singlecell.process.replicate_correlation import replicate_null_corr_coefs\n",
    "from singlecell.process import normalize_funcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3ded03",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Project root directory and path to results ########################\n",
    "mito_project_root_dir = \"/home/ubuntu/bucket/projects/2016_08_01_RadialMitochondriaDistribution_donna/\"\n",
    "save_results_dir = mito_project_root_dir + \"/workspace/results/jump_fq/\"\n",
    "\n",
    "with open(\n",
    "    \"/home/ubuntu/workspace_periscope/2022_PERISCOPE/common_files/annotated_gene_sets.json\"\n",
    ") as f:\n",
    "    gene_set_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7225b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotated_gene_sets.json  CORUM_humanComplexes.txt  \u001b[0m\u001b[01;31mSTRING_data.csv.gz\u001b[0m\r\n",
      "Barcodes.csv              README.md\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/ubuntu/workspace_periscope/2022_PERISCOPE/common_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63258585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from functools import reduce\n",
    "import gc\n",
    "\n",
    "\n",
    "def read_per_well_data(\n",
    "    input_data_dir,\n",
    "    annot,\n",
    "    prof_workspace_folder_name=\"profiles\",\n",
    "    fformat=\".parquet\",\n",
    "):\n",
    "    batches = annot[\"Batch\"].unique()\n",
    "\n",
    "    df_agg_all_batches_ls = []\n",
    "    for b in batches:\n",
    "        print(b)\n",
    "        #         if \"Metadata_Source\" in annot.columns:\n",
    "        source_str = annot.loc[\n",
    "            annot[\"Batch\"] == b, \"Metadata_Source\"\n",
    "        ].unique()[0]\n",
    "        #             print(source_str)\n",
    "        profile_path = (\n",
    "            input_data_dir\n",
    "            + source_str\n",
    "            + \"/workspace/\"\n",
    "            + prof_workspace_folder_name\n",
    "            + \"/\"\n",
    "        )\n",
    "        #         else:\n",
    "        #             profile_path = input_data_dir + \"/workspace/profiles/\"\n",
    "\n",
    "        df_sag_ls = []\n",
    "        plates_exist = os.listdir(profile_path + b)\n",
    "        plates_meta = annot.loc[annot[\"Batch\"] == b, \"Metadata_Plate\"].unique()\n",
    "        plates = set(plates_meta) & set(plates_exist)\n",
    "        for p in plates:\n",
    "            print(p)\n",
    "\n",
    "            fileName = profile_path + b + \"/\" + p + \"/\" + p + fformat\n",
    "            #             print(fileName)\n",
    "            if os.path.exists(fileName):\n",
    "                if fformat == \".parquet\":\n",
    "                    sc_df = pd.read_parquet(fileName)\n",
    "                elif fformat in [\".csv\", \".csv.gz\"]:\n",
    "                    sc_df = pd.read_csv(fileName)\n",
    "\n",
    "                #         per_site_aggregate=sc_df.groupby(['Metadata_Well','Metadata_Site']).mean()[feature_list+['Count_Cells']].reset_index()\n",
    "                sc_df[\"Metadata_Batch\"] = b\n",
    "                sc_df[\"Metadata_Plate\"] = p\n",
    "                df_sag_ls.append(sc_df)\n",
    "                del sc_df\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print(fileName, \" not exists\")\n",
    "\n",
    "        if df_sag_ls:\n",
    "            df_sag = pd.concat(df_sag_ls, axis=0)\n",
    "            df_agg_all_batches_ls.append(df_sag)\n",
    "\n",
    "    df_agg_all_batches = pd.concat(df_agg_all_batches_ls, axis=0)\n",
    "    return df_agg_all_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073b6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lincs_meta_cols = [\n",
    "    \"Metadata_broad_sample\",\n",
    "    \"Metadata_dose_recode\",\n",
    "    \"Metadata_pert_id\",\n",
    "    \"Metadata_pert_mfc_id\",\n",
    "    \"Metadata_InChIKey14\",\n",
    "    \"Metadata_pert_type\",\n",
    "    \"Metadata_moa\",\n",
    "    \"Metadata_target\",\n",
    "    \"Metadata_pert_id_dose\",\n",
    "    \"Metadata_pert_name\",\n",
    "]\n",
    "\n",
    "# lincs_meta_cols=['Metadata_broad_sample','Metadata_dose_recode','Metadata_pert_id','Metadata_pert_mfc_id',\\\n",
    "# 'Metadata_InChIKey14','Metadata_pert_type','Metadata_pert_id_dose']\n",
    "\n",
    "cdrp_meta_cols = [\n",
    "    \"Metadata_broad_sample\",\n",
    "    \"Metadata_mmoles_per_liter2\",\n",
    "    \"Metadata_pert_id\",\n",
    "    \"Metadata_Sample_Dose\",\n",
    "    \"Metadata_moa\",\n",
    "]\n",
    "jumporf_meta_cols = [\"Symbol\", \"broad_sample\"]\n",
    "jumpcrispr_meta_cols = [\"Metadata_NCBI_Gene_ID\", \"Metadata_Symbol\"]\n",
    "jumpcompound_meta_cols = [\"Metadata_InChIKey\", \"Metadata_InChI\"]\n",
    "taorf_meta_cols = [\n",
    "    \"Metadata_gene_name\",\n",
    "    \"Metadata_pert_name\",\n",
    "    \"Metadata_broad_sample\",\n",
    "    \"Metadata_moa\",\n",
    "]\n",
    "\n",
    "\n",
    "# jump_orf_params={'profiles_path':\"/home/ubuntu/jumpbucket/projects/2021_04_26_Production/workspace/backend/\",\\\n",
    "#                  'meta_cols':jumporf_meta_cols,\\\n",
    "#                  'pert_col':'broad_sample',\\\n",
    "#                  'target_features_list':target_features_list_orf_cdrp\n",
    "#                 }\n",
    "\n",
    "jump_orf_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0016-jump/\",\n",
    "    \"prof_workspace_folder_name\": \"profiles\",\n",
    "    \"pformat\": \".parquet\",\n",
    "    \"meta_cols\": jumporf_meta_cols,\n",
    "    \"pert_col\": \"Metadata_JCP2022\",\n",
    "    \"untreated_key_val\": [\"Metadata_pert_type\", \"negcon\"],\n",
    "}\n",
    "\n",
    "cdrp_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0012-wawer-bioactivecompoundprofiling/broad/workspace/backend/\",\n",
    "    \"meta_cols\": cdrp_meta_cols,\n",
    "    \"pert_col\": \"Metadata_Sample_Dose\",\n",
    "}\n",
    "# /home/ubuntu/bucket/projects/2015_10_05_DrugRepurposing_AravindSubramanian_GolubLab_Broad/workspace/backend/\n",
    "# https://cellpainting-gallery.s3.amazonaws.com/cpg0004-lincs/broad/workspace/backend/2016_04_01_a549_48hr_batch1/SQ00014812\n",
    "lincs_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0004-lincs/\",\n",
    "    \"prof_workspace_folder_name\": \"backend\",\n",
    "    \"pformat\": \".csv\",\n",
    "    \"meta_cols\": lincs_meta_cols,\n",
    "    \"pert_col\": \"Metadata_pert_id_dose\",\n",
    "    \"untreated_key_val\": [\"Metadata_pert_type\", \"control\"],\n",
    "}\n",
    "\n",
    "jump_crispr_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0016-jump/\",\n",
    "    \"prof_workspace_folder_name\": \"profiles\",\n",
    "    \"pformat\": \".parquet\",\n",
    "    \"meta_cols\": jumpcrispr_meta_cols,\n",
    "    \"pert_col\": \"Metadata_JCP2022\",\n",
    "    \"untreated_key_val\": [\"Metadata_Symbol\", \"non-targeting\"],\n",
    "}\n",
    "\n",
    "jump_compound_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0016-jump/\",\n",
    "    \"prof_workspace_folder_name\": \"profiles\",\n",
    "    \"pformat\": \".parquet\",\n",
    "    \"meta_cols\": jumpcompound_meta_cols,\n",
    "    \"pert_col\": \"Metadata_JCP2022\",\n",
    "    \"untreated_key_val\": [\"Metadata_JCP2022\", \"JCP2022_999999\"],\n",
    "}\n",
    "\n",
    "ta_orf_params = {\n",
    "    \"profiles_path\": \"/home/ubuntu/gallery/cpg0017-rohban-pathways/\",\n",
    "    \"prof_workspace_folder_name\": \"profiles\",\n",
    "    \"pformat\": \".csv.gz\",\n",
    "    \"meta_cols\": taorf_meta_cols,\n",
    "    \"pert_col\": \"Metadata_broad_sample\",\n",
    "    \"untreated_key_val\": [\"Metadata_pert_type\", \"Untreated\"],\n",
    "}\n",
    "\n",
    "ds_info_dict = {\n",
    "    \"jump_orf\": jump_orf_params,\n",
    "    \"CDRP\": cdrp_params,\n",
    "    \"lincs\": lincs_params,\n",
    "    \"lincs_g\": lincs_params,\n",
    "    \"jump_crispr\": jump_crispr_params,\n",
    "    \"jump_compound\": jump_compound_params,\n",
    "    \"taorf\": ta_orf_params,\n",
    "}\n",
    "# 'broad_sample', 'pert_type', 'control_type'\n",
    "\n",
    "# results=annot[['Symbol','broad_sample', 'pert_type', 'control_type']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# dataset='CDRP';dataset_meta_hue='Metadata_moa'\n",
    "# dataset='lincs';dataset_meta_hue='Metadata_moa'\n",
    "# dataset='jump_orf';dataset_meta_hue='Symbol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08af5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"jump_orf\", \"jump_crispr\"]\n",
    "\n",
    "symbol_col = {\n",
    "    \"jump_crispr\": \"Metadata_Symbol\",\n",
    "    \"jump_orf\": \"Metadata_Symbol\",\n",
    "    \"taorf\": \"Metadata_gene_name\",\n",
    "}\n",
    "\n",
    "df_ls = []\n",
    "# names=[]\n",
    "ds_symbols = {}\n",
    "ds_features = {}\n",
    "for dataset in datasets:\n",
    "    #     names.append(dataset)\n",
    "    annot = pd.read_csv(\n",
    "        mito_project_root_dir\n",
    "        + \"/workspace/metadata/preprocessed/annot_\"\n",
    "        + dataset\n",
    "        + \".csv\",\n",
    "        dtype={\"Metadata_Plate\": str},\n",
    "    )\n",
    "    if \"Metadata_Source\" not in annot.columns:\n",
    "        annot[\"Metadata_Source\"] = \"broad\"\n",
    "    # target_features_list = ds_info_dict[dataset][\"target_features_list\"]\n",
    "    # sources = ['source_5']\n",
    "    sources = annot[\"Metadata_Source\"].unique()\n",
    "    for si in sources:\n",
    "        file_path = (\n",
    "            save_results_dir\n",
    "            + \"/preprocessed_data/\"\n",
    "            + dataset\n",
    "            + \"_df_rep_level_scaled_\"\n",
    "            + si\n",
    "            + \".csv\"\n",
    "        )\n",
    "        if os.path.exists(file_path):\n",
    "            df_rep_level_scaled = pd.read_csv(file_path)\n",
    "\n",
    "            ds_symbols[dataset] = (\n",
    "                df_rep_level_scaled[symbol_col[dataset]].unique().tolist()\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cp_features,\n",
    "                cp_features_analysis_0,\n",
    "            ) = extract_cpfeature_names.extract_cpfeature_names(\n",
    "                df_rep_level_scaled\n",
    "            )\n",
    "\n",
    "            ds_features[dataset] = cp_features_analysis_0\n",
    "\n",
    "            #             df_rep_level_scaled['']\n",
    "\n",
    "            #         batch_names_cols = DS_X_featureQ_rank_df.columns[\n",
    "            #             DS_X_featureQ_rank_df.columns.str.contains(\"^average_std_score_\")\n",
    "            #         ].tolist()\n",
    "            df_ls.append(df_rep_level_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f2f465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap_symbols size:  5245 overlap_features size:  3378\n"
     ]
    }
   ],
   "source": [
    "overlap_symbols = list(\n",
    "    set.intersection(*(set(values) for values in ds_symbols.values()))\n",
    ")\n",
    "\n",
    "overlap_features = list(\n",
    "    set.intersection(*(set(values) for values in ds_features.values()))\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"overlap_symbols size: \",\n",
    "    len(overlap_symbols),\n",
    "    \"overlap_features size: \",\n",
    "    len(overlap_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f841c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec84e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate percentage of significant number of features from each channel\n",
    "def df_maker(gene_group, df_genes):\n",
    "    mito, cona, wga, dapi, phal = df_genes.Mito.mean(), df_genes.ConA.mean(), df_genes.WGA.mean(), df_genes.DAPI.mean(), df_genes.Phalloidin.mean()\n",
    "    sum_all = df_genes.Sum.mean()\n",
    "    data.loc[gene_group,'Mito'] = mito/sum_all*100\n",
    "    data.loc[gene_group,'ConA'] = cona/sum_all*100\n",
    "    data.loc[gene_group,'WGA'] = wga/sum_all*100\n",
    "    data.loc[gene_group,'DAPI'] = dapi/sum_all*100\n",
    "    data.loc[gene_group,'Phalloidin'] = phal/sum_all*100\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Organize the data into a dataframe\n",
    "gene_groups = ['Vacuolar-type ATPase','Protein O-mannosylation','Outer Mitochondrial Membrane Protein Complex',\n",
    "               'Cortical Cytoskeleton','DNA Polymerase Complex']\n",
    "data = pd.DataFrame(index=gene_groups)\n",
    "\n",
    "for gene_group in gene_groups:\n",
    "    gene_list = gene_set_dict[gene_group]\n",
    "    df_genes = df_sig_feature.loc[gene_list]\n",
    "    df_genes = df_genes.reset_index().query('index in @expressed_gene_list').query('index in @hit_list')\n",
    "    data = df_maker(gene_group, df_genes)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cef9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fraction of features per compartments for Fig 2E\n",
    "for group in list(data.index):\n",
    "    print(group)\n",
    "    group_name = group.replace(' ','_')\n",
    "    names = ['Mito','ER', 'Golgi/\\nMembrane', 'DNA','Actin']\n",
    "    size = data.loc[group].values\n",
    " \n",
    "    # Create a circle at the center of the plot\n",
    "    my_circle = plt.Circle( (0,0), 0.7, color='white')\n",
    "\n",
    "    # Custom wedges\n",
    "    plt.pie(size, \n",
    "            labels=names, \n",
    "            wedgeprops = { 'linewidth' : 7, 'edgecolor' : 'white' },\n",
    "            colors = ['lightcoral','orchid','lightblue','cornflowerblue','lightgreen'],\n",
    "            autopct='%1.0f%%', \n",
    "            pctdistance=0.83)\n",
    "    p = plt.gcf()\n",
    "    p.gca().add_artist(my_circle)\n",
    "    plt.savefig(os.path.join(output_folder,'figure_panels',f'Fig2E_A549_fraction_features_per_compartments_{group_name}.png'), \n",
    "                dpi=300,\n",
    "                facecolor='w', \n",
    "                edgecolor='w',\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
